{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"JiWER","text":"<p>JiWER is a simple and fast python package to evaluate an automatic speech recognition system. It supports the following measures:</p> <ol> <li>word error rate (WER)</li> <li>match error rate (MER)</li> <li>word information lost (WIL) </li> <li>word information preserved (WIP) </li> <li>character error rate (CER)</li> </ol> <p>These measures are computed with the use of the minimum-edit distance between one or more reference and hypothesis sentences. The minimum-edit distance is calculated using RapidFuzz, which uses C++ under the hood, and is therefore faster than a pure python implementation.</p>"},{"location":"#installation","title":"Installation","text":"<p>You should be able to install this package using uv: </p> <pre><code>$ uv add jiwer\n</code></pre> <p>Or, if you prefer old-fashioned pip and you're using Python &gt;= <code>3.8</code>:</p> <pre><code>$ pip install jiwer\n</code></pre>"},{"location":"cli/","title":"Command-line interface","text":"<p>JiWER provides a simple CLI, which should be available after installation. </p> <p>For details, see <code>jiwer --help</code>.</p> <pre><code>$ jiwer --help\nUsage: jiwer [OPTIONS]\n\n  JiWER is a python tool for computing the word-error-rate of ASR systems. To\n  use this CLI, store the reference and hypothesis sentences in a text file,\n  where each sentence is delimited by a new-line character. The text files are\n  expected to have an equal number of lines, unless the `-g` flag is used. The\n  `-g` flag joins computation of the WER by doing a global minimal alignment.\n\nOptions:\n  -r, --reference PATH   Path to new-line delimited text file of reference\n                         sentences.  [required]\n  -h, --hypothesis PATH  Path to new-line delimited text file of hypothesis\n                         sentences.  [required]\n  -c, --cer              Compute CER instead of WER.\n  -a, --align            Print alignment of each sentence.\n  -g, --global           Apply a global minimal alignment between reference\n                         and hypothesis sentences before computing the WER.\n  --help                 Show this message and exit.\n</code></pre> <p>Note that the CLI does not support custom pre-processing. Any pre-processing should be done on the text files manually before calling JiWER when using the CLI. </p>"},{"location":"usage/","title":"Usage","text":"<p>The most simple use-case is computing the word error rate between two strings:</p> <pre><code>from jiwer import wer\n\nreference = \"hello world\"\nhypothesis = \"hello duck\"\n\nerror = wer(reference, hypothesis)\n</code></pre> <p>Similarly, to get other measures:</p> <pre><code>import jiwer\n\nreference = \"hello world\"\nhypothesis = \"hello duck\"\n\nwer = jiwer.wer(reference, hypothesis)\nmer = jiwer.mer(reference, hypothesis)\nwil = jiwer.wil(reference, hypothesis)\n\n# faster, because `process_words` only needs to perform the heavy lifting once:\noutput = jiwer.process_words(reference, hypothesis)\nwer = output.wer\nmer = output.mer\nwil = output.wil\n</code></pre> <p>You can also compute the WER over multiple sentences:</p> <pre><code>from jiwer import wer\n\nreference = [\"hello world\", \"i like monthy python\"]\nhypothesis = [\"hello duck\", \"i like python\"]\n\nerror = wer(reference, hypothesis)\n</code></pre> <p>We also provide the character error rate:</p> <pre><code>import jiwer\n\nreference = [\"i can spell\", \"i hope\"]\nhypothesis = [\"i kan cpell\", \"i hop\"]\n\nerror = jiwer.cer(reference, hypothesis)\n\n# if you also want the alignment\noutput = jiwer.process_characters(reference, hypothesis)\nerror = output.cer\n</code></pre>"},{"location":"usage/#alignment","title":"Alignment","text":"<p>With <code>jiwer.process_words</code> and <code>jiwer.process_characters</code>, you get the alignment between the reference and hypothesis.</p> <p>We provide the alignment as a list of <code>AlignmentChunk</code> objects with attributes <code>type, ref_start_idx, ref_end_idx, hyp_start_idx, hyp_end_idx</code>, where <code>type</code> is one of <code>equal</code>, <code>substitute</code>, <code>delete</code>, or <code>insert</code>.</p> <p>This looks like the following:</p> <pre><code>import jiwer\n\nout = jiwer.process_words(\"short one here\", \"shoe order one\")\nprint(out.alignments)\n# [[[AlignmentChunk(type='insert', ref_start_idx=0, ref_end_idx=0, hyp_start_idx=0, hyp_end_idx=1), ...]]\n</code></pre> <p>To visualize the alignment, you can use <code>jiwer.visualize_alignment()</code></p> <p>For example:</p> <p><pre><code>import jiwer\n\nout = jiwer.process_words(\n    [\"short one here\", \"quite a bit of longer sentence\"],\n    [\"shoe order one\", \"quite bit of an even longest sentence here\"],\n)\n\nprint(jiwer.visualize_alignment(out))\n</code></pre> Gives the following output <pre><code>sentence 1\nREF: **** short one here\nHYP: shoe order one ****\n        I     S        D\n\nsentence 2\nREF: quite a bit of ** ****  longer sentence ****\nHYP: quite * bit of an even longest sentence here\n           D         I    I       S             I\n\nnumber of sentences: 2\nsubstitutions=2 deletions=2 insertions=4 hits=5\n\nmer=61.54%\nwil=74.75%\nwip=25.25%\nwer=88.89%\n</code></pre></p> <p>Note that it also possible to visualize the character-level alignment, simply use the output of <code>jiwer.process_characters()</code> instead. </p>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>alignment</li> <li>measures</li> <li>process</li> <li>transformations</li> <li>transforms</li> </ul>"},{"location":"reference/alignment/","title":"alignment","text":""},{"location":"reference/alignment/#alignment","title":"alignment","text":"<p>Utility method to visualize the alignment between one or more reference and hypothesis pairs.</p>"},{"location":"reference/alignment/#alignment.visualize_alignment","title":"visualize_alignment","text":"<pre><code>visualize_alignment(\n    output, show_measures=True, skip_correct=True\n)\n</code></pre> <p>Visualize the output of jiwer.process_words and jiwer.process_characters. The visualization shows the alignment between each processed reference and hypothesis pair. If <code>show_measures=True</code>, the output string will also contain all measures in the output.</p> <p>Parameters:</p> Name Type Description Default <code>output</code> <code>Union[WordOutput, CharacterOutput]</code> <p>The processed output of reference and hypothesis pair(s).</p> required <code>show_measures</code> <code>bool</code> <p>If enabled, the visualization will include measures like the WER            or CER</p> <code>True</code> <code>skip_correct</code> <code>bool</code> <p>If enabled, the visualization will exclude correct reference and hypothesis pairs</p> <code>True</code> <p>Returns:</p> Type Description <code>str</code> <p>The visualization as a string</p> Example <p>This code snippet <pre><code>import jiwer\n\nout = jiwer.process_words(\n    [\"short one here\", \"quite a bit of longer sentence\"],\n    [\"shoe order one\", \"quite bit of an even longest sentence here\"],\n)\n\nprint(jiwer.visualize_alignment(out))\n</code></pre> will produce this visualization: <pre><code>sentence 1\nREF:    # short one here\nHYP: shoe order one    *\n        I     S        D\n\nsentence 2\nREF: quite a bit of  #    #  longer sentence    #\nHYP: quite * bit of an even longest sentence here\n           D         I    I       S             I\n\nnumber of sentences: 2\nsubstitutions=2 deletions=2 insertions=4 hits=5\n\nmer=61.54%\nwil=74.75%\nwip=25.25%\nwer=88.89%\n</code></pre></p> <p>When <code>show_measures=False</code>, only the alignment will be printed:</p> <pre><code>sentence 1\nREF:    # short one here\nHYP: shoe order one    *\n        I     S        D\n\nsentence 2\nREF: quite a bit of  #    #  longer sentence    #\nHYP: quite * bit of an even longest sentence here\n           D         I    I       S             I\n</code></pre> Source code in <code>src/jiwer/alignment.py</code> <pre><code>def visualize_alignment(\n    output: Union[WordOutput, CharacterOutput],\n    show_measures: bool = True,\n    skip_correct: bool = True,\n) -&gt; str:\n    \"\"\"\n    Visualize the output of [jiwer.process_words][process.process_words] and\n    [jiwer.process_characters][process.process_characters]. The visualization\n    shows the alignment between each processed reference and hypothesis pair.\n    If `show_measures=True`, the output string will also contain all measures in the\n    output.\n\n    Args:\n        output: The processed output of reference and hypothesis pair(s).\n        show_measures: If enabled, the visualization will include measures like the WER\n                       or CER\n        skip_correct: If enabled, the visualization will exclude correct reference and hypothesis pairs\n\n    Returns:\n        (str): The visualization as a string\n\n    Example:\n        This code snippet\n        ```python\n        import jiwer\n\n        out = jiwer.process_words(\n            [\"short one here\", \"quite a bit of longer sentence\"],\n            [\"shoe order one\", \"quite bit of an even longest sentence here\"],\n        )\n\n        print(jiwer.visualize_alignment(out))\n        ```\n        will produce this visualization:\n        ```txt\n        sentence 1\n        REF:    # short one here\n        HYP: shoe order one    *\n                I     S        D\n\n        sentence 2\n        REF: quite a bit of  #    #  longer sentence    #\n        HYP: quite * bit of an even longest sentence here\n                   D         I    I       S             I\n\n        number of sentences: 2\n        substitutions=2 deletions=2 insertions=4 hits=5\n\n        mer=61.54%\n        wil=74.75%\n        wip=25.25%\n        wer=88.89%\n        ```\n\n        When `show_measures=False`, only the alignment will be printed:\n\n        ```txt\n        sentence 1\n        REF:    # short one here\n        HYP: shoe order one    *\n                I     S        D\n\n        sentence 2\n        REF: quite a bit of  #    #  longer sentence    #\n        HYP: quite * bit of an even longest sentence here\n                   D         I    I       S             I\n        ```\n    \"\"\"\n    references = output.references\n    hypothesis = output.hypotheses\n    alignment = output.alignments\n    is_cer = isinstance(output, CharacterOutput)\n\n    final_str = \"\"\n    for idx, (gt, hp, chunks) in enumerate(zip(references, hypothesis, alignment)):\n        if skip_correct and len(chunks) == 1 and chunks[0].type == \"equal\":\n            continue\n\n        final_str += f\"sentence {idx+1}\\n\"\n        final_str += _construct_comparison_string(\n            gt, hp, chunks, include_space_seperator=not is_cer\n        )\n        final_str += \"\\n\"\n\n    if show_measures:\n        final_str += f\"number of sentences: {len(alignment)}\\n\"\n        final_str += f\"substitutions={output.substitutions} \"\n        final_str += f\"deletions={output.deletions} \"\n        final_str += f\"insertions={output.insertions} \"\n        final_str += f\"hits={output.hits}\\n\"\n\n        if is_cer:\n            final_str += f\"\\ncer={output.cer*100:.2f}%\\n\"\n        else:\n            final_str += f\"\\nmer={output.mer*100:.2f}%\"\n            final_str += f\"\\nwil={output.wil*100:.2f}%\"\n            final_str += f\"\\nwip={output.wip*100:.2f}%\"\n            final_str += f\"\\nwer={output.wer*100:.2f}%\\n\"\n    else:\n        # remove last newline\n        final_str = final_str[:-1]\n\n    return final_str\n</code></pre>"},{"location":"reference/measures/","title":"measures","text":""},{"location":"reference/measures/#measures","title":"measures","text":"<p>Convenience methods for calculating a number of similarity error measures between a reference and hypothesis sentence. These measures are commonly used to measure the performance for an automatic speech recognition (ASR) system.</p> <p>The following measures are implemented:</p> <ul> <li>Word Error Rate (WER), which is where this library got its name from. This   has long been (and arguably still is) the de facto standard for computing   ASR performance.</li> <li>Match Error Rate (MER)</li> <li>Word Information Lost (WIL)</li> <li>Word Information Preserved (WIP)</li> <li>Character Error Rate (CER)</li> </ul> <p>Note that these functions merely call jiwer.process_words and jiwer.process_characters. It is more efficient to call <code>process_words</code> or <code>process_characters</code> and access the results from the jiwer.WordOutput and jiwer.CharacterOutput classes.</p>"},{"location":"reference/measures/#measures.cer","title":"cer","text":"<pre><code>cer(\n    reference=None,\n    hypothesis=None,\n    reference_transform=cer_default,\n    hypothesis_transform=cer_default,\n    return_dict=False,\n    truth=None,\n    truth_transform=None,\n)\n</code></pre> <p>Calculate the character error rate (CER) between one or more reference and hypothesis sentences.</p> <p>Parameters:</p> Name Type Description Default <code>reference</code> <code>Union[str, List[str]]</code> <p>The reference sentence(s)</p> <code>None</code> <code>hypothesis</code> <code>Union[str, List[str]]</code> <p>The hypothesis sentence(s)</p> <code>None</code> <code>reference_transform</code> <code>Union[Compose, AbstractTransform]</code> <p>The transformation(s) to apply to the reference string(s)</p> <code>cer_default</code> <code>hypothesis_transform</code> <code>Union[Compose, AbstractTransform]</code> <p>The transformation(s) to apply to the hypothesis string(s)</p> <code>cer_default</code> <code>return_dict</code> <code>bool</code> <p>Deprecated option to return the more results in a dict instead of          returning only the cer as a single float value</p> <code>False</code> <code>truth</code> <code>Union[str, List[str]]</code> <p>Deprecated, renamed to <code>reference</code></p> <code>None</code> <code>truth_transform</code> <code>Union[Compose, AbstractTransform]</code> <p>Deprecated, renamed to <code>reference_transform</code></p> <code>None</code> Deprecated <p>Argument <code>return_dict</code> will be deprecated. Please use jiwer.process_characters instead.</p> <p>Arguments <code>truth</code> and <code>truth_transform</code> have been renamed to respectively <code>reference</code> and <code>reference_transform</code>. Therefore, the keyword arguments  <code>truth</code> and <code>truth_transform</code> will be removed in the next release.  At the same time, <code>reference</code> and <code>reference_transform</code> will lose their  default value.</p> <p>Returns:</p> Type Description <code>float</code> <p>The character error rate of the given reference and hypothesis      sentence(s).</p> Source code in <code>src/jiwer/measures.py</code> <pre><code>def cer(\n    reference: Union[str, List[str]] = None,\n    hypothesis: Union[str, List[str]] = None,\n    reference_transform: Union[tr.Compose, tr.AbstractTransform] = cer_default,\n    hypothesis_transform: Union[tr.Compose, tr.AbstractTransform] = cer_default,\n    return_dict: bool = False,\n    truth: Union[str, List[str]] = None,\n    truth_transform: Union[tr.Compose, tr.AbstractTransform] = None,\n) -&gt; Union[float, Dict[str, Any]]:\n    \"\"\"\n    Calculate the character error rate (CER) between one or more reference and\n    hypothesis sentences.\n\n    Args:\n        reference: The reference sentence(s)\n        hypothesis: The hypothesis sentence(s)\n        reference_transform: The transformation(s) to apply to the reference string(s)\n        hypothesis_transform: The transformation(s) to apply to the hypothesis string(s)\n        return_dict: Deprecated option to return the more results in a dict instead of\n                     returning only the cer as a single float value\n        truth: Deprecated, renamed to `reference`\n        truth_transform: Deprecated, renamed to `reference_transform`\n\n    Deprecated:\n        Argument `return_dict` will be deprecated. Please use\n        [jiwer.process_characters][process.process_characters] instead.\n\n        Arguments `truth` and `truth_transform` have been renamed to respectively\n        `reference` and `reference_transform`. Therefore, the keyword arguments\n         `truth` and `truth_transform` will be removed in the next release.\n         At the same time, `reference` and `reference_transform` will lose their\n         default value.\n\n    Returns:\n        (float): The character error rate of the given reference and hypothesis\n                 sentence(s).\n    \"\"\"\n    (\n        reference,\n        hypothesis,\n        reference_transform,\n        hypothesis_transform,\n    ) = _deprecate_truth(\n        reference=reference,\n        hypothesis=hypothesis,\n        truth=truth,\n        reference_transform=reference_transform,\n        truth_transform=truth_transform,\n        hypothesis_transform=hypothesis_transform,\n    )\n\n    output = process_characters(\n        reference, hypothesis, reference_transform, hypothesis_transform\n    )\n\n    if return_dict:\n        warnings.warn(\n            DeprecationWarning(\n                \"`return_dict` is deprecated, \"\n                \"please use jiwer.process_characters() instead.\"\n            )\n        )\n        return {\n            \"cer\": output.cer,\n            \"hits\": output.hits,\n            \"substitutions\": output.substitutions,\n            \"deletions\": output.deletions,\n            \"insertions\": output.insertions,\n        }\n    else:\n        return output.cer\n</code></pre>"},{"location":"reference/measures/#measures.compute_measures","title":"compute_measures","text":"<pre><code>compute_measures(\n    truth,\n    hypothesis,\n    truth_transform=wer_default,\n    hypothesis_transform=wer_default,\n)\n</code></pre> <p>Efficiently computes all measures using only one function call.</p> Deprecated <p>Deprecated method. Superseded by jiwer.process_words. This method will be removed on next release.</p> <p>Parameters:</p> Name Type Description Default <code>truth</code> <code>Union[str, List[str]]</code> <p>The reference sentence(s)</p> required <code>hypothesis</code> <code>Union[str, List[str]]</code> <p>The hypothesis sentence(s)</p> required <code>truth_transform</code> <code>Union[Compose, AbstractTransform]</code> <p>The transformation(s) to apply to the reference string(s)</p> <code>wer_default</code> <code>hypothesis_transform</code> <code>Union[Compose, AbstractTransform]</code> <p>The transformation(s) to apply to the hypothesis string(s)</p> <code>wer_default</code> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary containing key-value pairs for all measures.</p> Source code in <code>src/jiwer/measures.py</code> <pre><code>def compute_measures(\n    truth: Union[str, List[str]],\n    hypothesis: Union[str, List[str]],\n    truth_transform: Union[tr.Compose, tr.AbstractTransform] = wer_default,\n    hypothesis_transform: Union[tr.Compose, tr.AbstractTransform] = wer_default,\n) -&gt; Dict[str, Any]:\n    \"\"\"\n    Efficiently computes all measures using only one function call.\n\n    Deprecated:\n        Deprecated method. Superseded by [jiwer.process_words][process.process_words].\n        This method will be removed on next release.\n\n    Args:\n        truth: The reference sentence(s)\n        hypothesis: The hypothesis sentence(s)\n        truth_transform: The transformation(s) to apply to the reference string(s)\n        hypothesis_transform: The transformation(s) to apply to the hypothesis string(s)\n\n    Returns:\n        (dict): A dictionary containing key-value pairs for all measures.\n\n    \"\"\"\n    warnings.warn(\n        DeprecationWarning(\n            \"jiwer.compute_measures() is deprecated. Please use jiwer.process_words().\"\n        )\n    )\n\n    output = process_words(\n        reference=truth,\n        hypothesis=hypothesis,\n        reference_transform=truth_transform,\n        hypothesis_transform=hypothesis_transform,\n    )\n\n    return {\n        \"wer\": output.wer,\n        \"mer\": output.mer,\n        \"wil\": output.wil,\n        \"wip\": output.wip,\n        \"hits\": output.hits,\n        \"substitutions\": output.substitutions,\n        \"deletions\": output.deletions,\n        \"insertions\": output.insertions,\n        \"ops\": output.alignments,\n        \"truth\": output.references,\n        \"hypothesis\": output.hypotheses,\n    }\n</code></pre>"},{"location":"reference/measures/#measures.mer","title":"mer","text":"<pre><code>mer(\n    reference=None,\n    hypothesis=None,\n    reference_transform=wer_default,\n    hypothesis_transform=wer_default,\n    truth=None,\n    truth_transform=None,\n)\n</code></pre> <p>Calculate the match error rate (MER) between one or more reference and hypothesis sentences.</p> <p>Parameters:</p> Name Type Description Default <code>reference</code> <code>Union[str, List[str]]</code> <p>The reference sentence(s)</p> <code>None</code> <code>hypothesis</code> <code>Union[str, List[str]]</code> <p>The hypothesis sentence(s)</p> <code>None</code> <code>reference_transform</code> <code>Union[Compose, AbstractTransform]</code> <p>The transformation(s) to apply to the reference string(s)</p> <code>wer_default</code> <code>hypothesis_transform</code> <code>Union[Compose, AbstractTransform]</code> <p>The transformation(s) to apply to the hypothesis string(s)</p> <code>wer_default</code> <code>truth</code> <code>Union[str, List[str]]</code> <p>Deprecated, renamed to <code>reference</code></p> <code>None</code> <code>truth_transform</code> <code>Union[Compose, AbstractTransform]</code> <p>Deprecated, renamed to <code>reference_transform</code></p> <code>None</code> Deprecated <p>Arguments <code>truth</code> and <code>truth_transform</code> have been renamed to respectively <code>reference</code> and <code>reference_transform</code>. Therefore, the keyword arguments  <code>truth</code> and <code>truth_transform</code> will be removed in the next release.  At the same time, <code>reference</code> and <code>reference_transform</code> will lose their  default value.</p> <p>Returns:</p> Type Description <code>float</code> <p>The match error rate of the given reference and      hypothesis sentence(s).</p> Source code in <code>src/jiwer/measures.py</code> <pre><code>def mer(\n    reference: Union[str, List[str]] = None,\n    hypothesis: Union[str, List[str]] = None,\n    reference_transform: Union[tr.Compose, tr.AbstractTransform] = wer_default,\n    hypothesis_transform: Union[tr.Compose, tr.AbstractTransform] = wer_default,\n    truth: Union[str, List[str]] = None,\n    truth_transform: Union[tr.Compose, tr.AbstractTransform] = None,\n) -&gt; float:\n    \"\"\"\n    Calculate the match error rate (MER) between one or more reference and\n    hypothesis sentences.\n\n    Args:\n        reference: The reference sentence(s)\n        hypothesis: The hypothesis sentence(s)\n        reference_transform: The transformation(s) to apply to the reference string(s)\n        hypothesis_transform: The transformation(s) to apply to the hypothesis string(s)\n        truth: Deprecated, renamed to `reference`\n        truth_transform: Deprecated, renamed to `reference_transform`\n\n    Deprecated:\n        Arguments `truth` and `truth_transform` have been renamed to respectively\n        `reference` and `reference_transform`. Therefore, the keyword arguments\n         `truth` and `truth_transform` will be removed in the next release.\n         At the same time, `reference` and `reference_transform` will lose their\n         default value.\n\n    Returns:\n        (float): The match error rate of the given reference and\n                 hypothesis sentence(s).\n    \"\"\"\n    (\n        reference,\n        hypothesis,\n        reference_transform,\n        hypothesis_transform,\n    ) = _deprecate_truth(\n        reference=reference,\n        hypothesis=hypothesis,\n        truth=truth,\n        reference_transform=reference_transform,\n        truth_transform=truth_transform,\n        hypothesis_transform=hypothesis_transform,\n    )\n\n    output = process_words(\n        reference, hypothesis, reference_transform, hypothesis_transform\n    )\n\n    return output.mer\n</code></pre>"},{"location":"reference/measures/#measures.wer","title":"wer","text":"<pre><code>wer(\n    reference=None,\n    hypothesis=None,\n    reference_transform=wer_default,\n    hypothesis_transform=wer_default,\n    truth=None,\n    truth_transform=None,\n)\n</code></pre> <p>Calculate the word error rate (WER) between one or more reference and hypothesis sentences.</p> <p>Parameters:</p> Name Type Description Default <code>reference</code> <code>Union[str, List[str]]</code> <p>The reference sentence(s)</p> <code>None</code> <code>hypothesis</code> <code>Union[str, List[str]]</code> <p>The hypothesis sentence(s)</p> <code>None</code> <code>reference_transform</code> <code>Union[Compose, AbstractTransform]</code> <p>The transformation(s) to apply to the reference string(s)</p> <code>wer_default</code> <code>hypothesis_transform</code> <code>Union[Compose, AbstractTransform]</code> <p>The transformation(s) to apply to the hypothesis string(s)</p> <code>wer_default</code> <code>truth</code> <code>Union[str, List[str]]</code> <p>Deprecated, renamed to <code>reference</code></p> <code>None</code> <code>truth_transform</code> <code>Union[Compose, AbstractTransform]</code> <p>Deprecated, renamed to <code>reference_transform</code></p> <code>None</code> Deprecated <p>Arguments <code>truth</code> and <code>truth_transform</code> have been renamed to respectively <code>reference</code> and <code>reference_transform</code>. Therefore, the keyword arguments  <code>truth</code> and <code>truth_transform</code> will be removed in the next release.  At the same time, <code>reference</code> and <code>reference_transform</code> will lose their  default value.</p> <p>Returns:</p> Type Description <code>float</code> <p>The word error rate of the given reference and      hypothesis sentence(s).</p> Source code in <code>src/jiwer/measures.py</code> <pre><code>def wer(\n    reference: Union[str, List[str]] = None,\n    hypothesis: Union[str, List[str]] = None,\n    reference_transform: Union[tr.Compose, tr.AbstractTransform] = wer_default,\n    hypothesis_transform: Union[tr.Compose, tr.AbstractTransform] = wer_default,\n    truth: Union[str, List[str]] = None,\n    truth_transform: Union[tr.Compose, tr.AbstractTransform] = None,\n) -&gt; float:\n    \"\"\"\n    Calculate the word error rate (WER) between one or more reference and\n    hypothesis sentences.\n\n    Args:\n        reference: The reference sentence(s)\n        hypothesis: The hypothesis sentence(s)\n        reference_transform: The transformation(s) to apply to the reference string(s)\n        hypothesis_transform: The transformation(s) to apply to the hypothesis string(s)\n        truth: Deprecated, renamed to `reference`\n        truth_transform: Deprecated, renamed to `reference_transform`\n\n    Deprecated:\n        Arguments `truth` and `truth_transform` have been renamed to respectively\n        `reference` and `reference_transform`. Therefore, the keyword arguments\n         `truth` and `truth_transform` will be removed in the next release.\n         At the same time, `reference` and `reference_transform` will lose their\n         default value.\n\n    Returns:\n        (float): The word error rate of the given reference and\n                 hypothesis sentence(s).\n    \"\"\"\n    (\n        reference,\n        hypothesis,\n        reference_transform,\n        hypothesis_transform,\n    ) = _deprecate_truth(\n        reference=reference,\n        hypothesis=hypothesis,\n        truth=truth,\n        reference_transform=reference_transform,\n        truth_transform=truth_transform,\n        hypothesis_transform=hypothesis_transform,\n    )\n\n    output = process_words(\n        reference, hypothesis, reference_transform, hypothesis_transform\n    )\n    return output.wer\n</code></pre>"},{"location":"reference/measures/#measures.wil","title":"wil","text":"<pre><code>wil(\n    reference=None,\n    hypothesis=None,\n    reference_transform=wer_default,\n    hypothesis_transform=wer_default,\n    truth=None,\n    truth_transform=None,\n)\n</code></pre> <p>Calculate the word information lost (WIL) between one or more reference and hypothesis sentences.</p> <p>Parameters:</p> Name Type Description Default <code>reference</code> <code>Union[str, List[str]]</code> <p>The reference sentence(s)</p> <code>None</code> <code>hypothesis</code> <code>Union[str, List[str]]</code> <p>The hypothesis sentence(s)</p> <code>None</code> <code>reference_transform</code> <code>Union[Compose, AbstractTransform]</code> <p>The transformation(s) to apply to the reference string(s)</p> <code>wer_default</code> <code>hypothesis_transform</code> <code>Union[Compose, AbstractTransform]</code> <p>The transformation(s) to apply to the hypothesis string(s)</p> <code>wer_default</code> <code>truth</code> <code>Union[str, List[str]]</code> <p>Deprecated, renamed to <code>reference</code></p> <code>None</code> <code>truth_transform</code> <code>Union[Compose, AbstractTransform]</code> <p>Deprecated, renamed to <code>reference_transform</code></p> <code>None</code> Deprecated <p>Arguments <code>truth</code> and <code>truth_transform</code> have been renamed to respectively <code>reference</code> and <code>reference_transform</code>. Therefore, the keyword arguments <code>truth</code> and <code>truth_transform</code> will be removed in the next release.  At the same time, <code>reference</code> and <code>reference_transform</code> will lose their  default value.</p> <p>Returns:</p> Type Description <code>float</code> <p>The word information lost of the given reference and      hypothesis sentence(s).</p> Source code in <code>src/jiwer/measures.py</code> <pre><code>def wil(\n    reference: Union[str, List[str]] = None,\n    hypothesis: Union[str, List[str]] = None,\n    reference_transform: Union[tr.Compose, tr.AbstractTransform] = wer_default,\n    hypothesis_transform: Union[tr.Compose, tr.AbstractTransform] = wer_default,\n    truth: Union[str, List[str]] = None,\n    truth_transform: Union[tr.Compose, tr.AbstractTransform] = None,\n) -&gt; float:\n    \"\"\"\n    Calculate the word information lost (WIL) between one or more reference and\n    hypothesis sentences.\n\n    Args:\n        reference: The reference sentence(s)\n        hypothesis: The hypothesis sentence(s)\n        reference_transform: The transformation(s) to apply to the reference string(s)\n        hypothesis_transform: The transformation(s) to apply to the hypothesis string(s)\n        truth: Deprecated, renamed to `reference`\n        truth_transform: Deprecated, renamed to `reference_transform`\n\n    Deprecated:\n        Arguments `truth` and `truth_transform` have been renamed to respectively\n        `reference` and `reference_transform`. Therefore, the keyword arguments\n        `truth` and `truth_transform` will be removed in the next release.\n         At the same time, `reference` and `reference_transform` will lose their\n         default value.\n\n    Returns:\n        (float): The word information lost of the given reference and\n                 hypothesis sentence(s).\n    \"\"\"\n    (\n        reference,\n        hypothesis,\n        reference_transform,\n        hypothesis_transform,\n    ) = _deprecate_truth(\n        reference=reference,\n        hypothesis=hypothesis,\n        truth=truth,\n        reference_transform=reference_transform,\n        truth_transform=truth_transform,\n        hypothesis_transform=hypothesis_transform,\n    )\n\n    output = process_words(\n        reference, hypothesis, reference_transform, hypothesis_transform\n    )\n\n    return output.wil\n</code></pre>"},{"location":"reference/measures/#measures.wip","title":"wip","text":"<pre><code>wip(\n    reference=None,\n    hypothesis=None,\n    reference_transform=wer_default,\n    hypothesis_transform=wer_default,\n    truth=None,\n    truth_transform=None,\n)\n</code></pre> <p>Calculate the word information preserved (WIP) between one or more reference and hypothesis sentences.</p> <p>Parameters:</p> Name Type Description Default <code>reference</code> <code>Union[str, List[str]]</code> <p>The reference sentence(s)</p> <code>None</code> <code>hypothesis</code> <code>Union[str, List[str]]</code> <p>The hypothesis sentence(s)</p> <code>None</code> <code>reference_transform</code> <code>Union[Compose, AbstractTransform]</code> <p>The transformation(s) to apply to the reference string(s)</p> <code>wer_default</code> <code>hypothesis_transform</code> <code>Union[Compose, AbstractTransform]</code> <p>The transformation(s) to apply to the hypothesis string(s)</p> <code>wer_default</code> <code>truth</code> <code>Union[str, List[str]]</code> <p>Deprecated, renamed to <code>reference</code></p> <code>None</code> <code>truth_transform</code> <code>Union[Compose, AbstractTransform]</code> <p>Deprecated, renamed to <code>reference_transform</code></p> <code>None</code> Deprecated <p>Arguments <code>truth</code> and <code>truth_transform</code> have been renamed to respectively <code>reference</code> and <code>reference_transform</code>. Therefore, the keyword arguments  <code>truth</code> and <code>truth_transform</code> will be removed in the next release.  At the same time, <code>reference</code> and <code>reference_transform</code> will lose their  default value.</p> <p>Returns:</p> Type Description <code>float</code> <p>The word information preserved of the given reference and      hypothesis sentence(s).</p> Source code in <code>src/jiwer/measures.py</code> <pre><code>def wip(\n    reference: Union[str, List[str]] = None,\n    hypothesis: Union[str, List[str]] = None,\n    reference_transform: Union[tr.Compose, tr.AbstractTransform] = wer_default,\n    hypothesis_transform: Union[tr.Compose, tr.AbstractTransform] = wer_default,\n    truth: Union[str, List[str]] = None,\n    truth_transform: Union[tr.Compose, tr.AbstractTransform] = None,\n) -&gt; float:\n    \"\"\"\n    Calculate the word information preserved (WIP) between one or more reference and\n    hypothesis sentences.\n\n    Args:\n        reference: The reference sentence(s)\n        hypothesis: The hypothesis sentence(s)\n        reference_transform: The transformation(s) to apply to the reference string(s)\n        hypothesis_transform: The transformation(s) to apply to the hypothesis string(s)\n        truth: Deprecated, renamed to `reference`\n        truth_transform: Deprecated, renamed to `reference_transform`\n\n    Deprecated:\n        Arguments `truth` and `truth_transform` have been renamed to respectively\n        `reference` and `reference_transform`. Therefore, the keyword arguments\n         `truth` and `truth_transform` will be removed in the next release.\n         At the same time, `reference` and `reference_transform` will lose their\n         default value.\n\n    Returns:\n        (float): The word information preserved of the given reference and\n                 hypothesis sentence(s).\n    \"\"\"\n    (\n        reference,\n        hypothesis,\n        reference_transform,\n        hypothesis_transform,\n    ) = _deprecate_truth(\n        reference=reference,\n        hypothesis=hypothesis,\n        truth=truth,\n        reference_transform=reference_transform,\n        truth_transform=truth_transform,\n        hypothesis_transform=hypothesis_transform,\n    )\n\n    output = process_words(\n        reference, hypothesis, reference_transform, hypothesis_transform\n    )\n\n    return output.wip\n</code></pre>"},{"location":"reference/process/","title":"process","text":""},{"location":"reference/process/#process","title":"process","text":"<p>The core algorithm(s) for processing a one or more reference and hypothesis sentences so that measures can be computed and an alignment can be visualized.</p>"},{"location":"reference/process/#process.AlignmentChunk","title":"AlignmentChunk  <code>dataclass</code>","text":"<p>Define an alignment between two subsequence of the reference and hypothesis.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>str</code> <p>one of <code>equal</code>, <code>substitute</code>, <code>insert</code>, or <code>delete</code></p> <code>ref_start_idx</code> <code>int</code> <p>the start index of the reference subsequence</p> <code>ref_end_idx</code> <code>int</code> <p>the end index of the reference subsequence</p> <code>hyp_start_idx</code> <code>int</code> <p>the start index of the hypothesis subsequence</p> <code>hyp_end_idx</code> <code>int</code> <p>the end index of the hypothesis subsequence</p> Source code in <code>src/jiwer/process.py</code> <pre><code>@dataclass\nclass AlignmentChunk:\n    \"\"\"\n    Define an alignment between two subsequence of the reference and hypothesis.\n\n    Attributes:\n        type: one of `equal`, `substitute`, `insert`, or `delete`\n        ref_start_idx: the start index of the reference subsequence\n        ref_end_idx: the end index of the reference subsequence\n        hyp_start_idx: the start index of the hypothesis subsequence\n        hyp_end_idx: the end index of the hypothesis subsequence\n    \"\"\"\n\n    type: str\n\n    ref_start_idx: int\n    ref_end_idx: int\n\n    hyp_start_idx: int\n    hyp_end_idx: int\n\n    def __post_init__(self):\n        if self.type not in [\"replace\", \"insert\", \"delete\", \"equal\", \"substitute\"]:\n            raise ValueError(\"\")\n\n        # rapidfuzz uses replace instead of substitute... For consistency, we change it\n        if self.type == \"replace\":\n            self.type = \"substitute\"\n\n        if self.ref_start_idx &gt; self.ref_end_idx:\n            raise ValueError(\n                f\"ref_start_idx={self.ref_start_idx} \"\n                f\"is larger \"\n                f\"than ref_end_idx={self.ref_end_idx}\"\n            )\n        if self.hyp_start_idx &gt; self.hyp_end_idx:\n            raise ValueError(\n                f\"hyp_start_idx={self.hyp_start_idx} \"\n                f\"is larger \"\n                f\"than hyp_end_idx={self.hyp_end_idx}\"\n            )\n</code></pre>"},{"location":"reference/process/#process.CharacterOutput","title":"CharacterOutput  <code>dataclass</code>","text":"<p>The output of calculating the character-level levenshtein distance between one or more reference and hypothesis sentence(s).</p> <p>Attributes:</p> Name Type Description <code>references</code> <code>List[List[str]]</code> <p>The reference sentences</p> <code>hypotheses</code> <code>List[List[str]]</code> <p>The hypothesis sentences</p> <code>alignments</code> <code>List[List[AlignmentChunk]]</code> <p>The alignment between reference and hypothesis sentences</p> <code>cer</code> <code>float</code> <p>The character error rate</p> <code>hits</code> <code>int</code> <p>The number of correct characters between reference and hypothesis   sentences</p> <code>substitutions</code> <code>int</code> <p>The number of substitutions required to transform hypothesis            sentences to reference sentences</p> <code>insertions</code> <code>int</code> <p>The number of insertions required to transform hypothesis            sentences to reference sentences</p> <code>deletions</code> <code>int</code> <p>The number of deletions required to transform hypothesis            sentences to reference sentences</p> Source code in <code>src/jiwer/process.py</code> <pre><code>@dataclass\nclass CharacterOutput:\n    \"\"\"\n    The output of calculating the character-level levenshtein distance between one or\n    more reference and hypothesis sentence(s).\n\n    Attributes:\n        references: The reference sentences\n        hypotheses: The hypothesis sentences\n        alignments: The alignment between reference and hypothesis sentences\n        cer: The character error rate\n        hits: The number of correct characters between reference and hypothesis\n              sentences\n        substitutions: The number of substitutions required to transform hypothesis\n                       sentences to reference sentences\n        insertions: The number of insertions required to transform hypothesis\n                       sentences to reference sentences\n        deletions: The number of deletions required to transform hypothesis\n                       sentences to reference sentences\n    \"\"\"\n\n    # processed input data\n    references: List[List[str]]\n    hypotheses: List[List[str]]\n\n    # alignment\n    alignments: List[List[AlignmentChunk]]\n\n    # measures\n    cer: float\n\n    # stats\n    hits: int\n    substitutions: int\n    insertions: int\n    deletions: int\n</code></pre>"},{"location":"reference/process/#process.WordOutput","title":"WordOutput  <code>dataclass</code>","text":"<p>The output of calculating the word-level levenshtein distance between one or more reference and hypothesis sentence(s).</p> <p>Attributes:</p> Name Type Description <code>references</code> <code>List[List[str]]</code> <p>The reference sentences</p> <code>hypotheses</code> <code>List[List[str]]</code> <p>The hypothesis sentences</p> <code>alignments</code> <code>List[List[AlignmentChunk]]</code> <p>The alignment between reference and hypothesis sentences</p> <code>wer</code> <code>float</code> <p>The word error rate</p> <code>mer</code> <code>float</code> <p>The match error rate</p> <code>wil</code> <code>float</code> <p>The word information lost measure</p> <code>wip</code> <code>float</code> <p>The word information preserved measure</p> <code>hits</code> <code>int</code> <p>The number of correct words between reference and hypothesis sentences</p> <code>substitutions</code> <code>int</code> <p>The number of substitutions required to transform hypothesis            sentences to reference sentences</p> <code>insertions</code> <code>int</code> <p>The number of insertions required to transform hypothesis            sentences to reference sentences</p> <code>deletions</code> <code>int</code> <p>The number of deletions required to transform hypothesis            sentences to reference sentences</p> Source code in <code>src/jiwer/process.py</code> <pre><code>@dataclass\nclass WordOutput:\n    \"\"\"\n    The output of calculating the word-level levenshtein distance between one or more\n    reference and hypothesis sentence(s).\n\n    Attributes:\n        references: The reference sentences\n        hypotheses: The hypothesis sentences\n        alignments: The alignment between reference and hypothesis sentences\n        wer: The word error rate\n        mer: The match error rate\n        wil: The word information lost measure\n        wip: The word information preserved measure\n        hits: The number of correct words between reference and hypothesis sentences\n        substitutions: The number of substitutions required to transform hypothesis\n                       sentences to reference sentences\n        insertions: The number of insertions required to transform hypothesis\n                       sentences to reference sentences\n        deletions: The number of deletions required to transform hypothesis\n                       sentences to reference sentences\n\n    \"\"\"\n\n    # processed input data\n    references: List[List[str]]\n    hypotheses: List[List[str]]\n\n    # alignment\n    alignments: List[List[AlignmentChunk]]\n\n    # measures\n    wer: float\n    mer: float\n    wil: float\n    wip: float\n\n    # stats\n    hits: int\n    substitutions: int\n    insertions: int\n    deletions: int\n</code></pre>"},{"location":"reference/process/#process.process_characters","title":"process_characters","text":"<pre><code>process_characters(\n    reference,\n    hypothesis,\n    reference_transform=cer_default,\n    hypothesis_transform=cer_default,\n)\n</code></pre> <p>Compute the character-level levenshtein distance and alignment between one or more reference and hypothesis sentences. Based on the result, the character error rate can be computed.</p> <p>Note that the by default this method includes space (<code></code>) as a character over which the error rate is computed. If this is not desired, the reference and hypothesis transform need to be modified.</p> <p>Parameters:</p> Name Type Description Default <code>reference</code> <code>Union[str, List[str]]</code> <p>The reference sentence(s)</p> required <code>hypothesis</code> <code>Union[str, List[str]]</code> <p>The hypothesis sentence(s)</p> required <code>reference_transform</code> <code>Union[Compose, AbstractTransform]</code> <p>The transformation(s) to apply to the reference string(s)</p> <code>cer_default</code> <code>hypothesis_transform</code> <code>Union[Compose, AbstractTransform]</code> <p>The transformation(s) to apply to the hypothesis string(s)</p> <code>cer_default</code> <p>Returns:</p> Type Description <code>CharacterOutput</code> <p>The processed reference and hypothesis sentences.</p> Source code in <code>src/jiwer/process.py</code> <pre><code>def process_characters(\n    reference: Union[str, List[str]],\n    hypothesis: Union[str, List[str]],\n    reference_transform: Union[tr.Compose, tr.AbstractTransform] = cer_default,\n    hypothesis_transform: Union[tr.Compose, tr.AbstractTransform] = cer_default,\n) -&gt; CharacterOutput:\n    \"\"\"\n    Compute the character-level levenshtein distance and alignment between one or more\n    reference and hypothesis sentences. Based on the result, the character error rate\n    can be computed.\n\n    Note that the by default this method includes space (` `) as a\n    character over which the error rate is computed. If this is not desired, the\n    reference and hypothesis transform need to be modified.\n\n    Args:\n        reference: The reference sentence(s)\n        hypothesis: The hypothesis sentence(s)\n        reference_transform: The transformation(s) to apply to the reference string(s)\n        hypothesis_transform: The transformation(s) to apply to the hypothesis string(s)\n\n    Returns:\n        (CharacterOutput): The processed reference and hypothesis sentences.\n\n    \"\"\"\n    # make sure the transforms end with tr.ReduceToListOfListOfChars(),\n\n    # it's the same as word processing, just every word is of length 1\n    result = process_words(\n        reference, hypothesis, reference_transform, hypothesis_transform\n    )\n\n    return CharacterOutput(\n        references=result.references,\n        hypotheses=result.hypotheses,\n        alignments=result.alignments,\n        cer=result.wer,\n        hits=result.hits,\n        substitutions=result.substitutions,\n        insertions=result.insertions,\n        deletions=result.deletions,\n    )\n</code></pre>"},{"location":"reference/process/#process.process_words","title":"process_words","text":"<pre><code>process_words(\n    reference,\n    hypothesis,\n    reference_transform=wer_default,\n    hypothesis_transform=wer_default,\n)\n</code></pre> <p>Compute the word-level levenshtein distance and alignment between one or more reference and hypothesis sentences. Based on the result, multiple measures can be computed, such as the word error rate.</p> <p>Parameters:</p> Name Type Description Default <code>reference</code> <code>Union[str, List[str]]</code> <p>The reference sentence(s)</p> required <code>hypothesis</code> <code>Union[str, List[str]]</code> <p>The hypothesis sentence(s)</p> required <code>reference_transform</code> <code>Union[Compose, AbstractTransform]</code> <p>The transformation(s) to apply to the reference string(s)</p> <code>wer_default</code> <code>hypothesis_transform</code> <code>Union[Compose, AbstractTransform]</code> <p>The transformation(s) to apply to the hypothesis string(s)</p> <code>wer_default</code> <p>Returns:</p> Type Description <code>WordOutput</code> <p>The processed reference and hypothesis sentences</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If one or more references are empty strings</p> <code>ValueError</code> <p>If after applying transforms, reference and hypothesis lengths don't match</p> Source code in <code>src/jiwer/process.py</code> <pre><code>def process_words(\n    reference: Union[str, List[str]],\n    hypothesis: Union[str, List[str]],\n    reference_transform: Union[tr.Compose, tr.AbstractTransform] = wer_default,\n    hypothesis_transform: Union[tr.Compose, tr.AbstractTransform] = wer_default,\n) -&gt; WordOutput:\n    \"\"\"\n    Compute the word-level levenshtein distance and alignment between one or more\n    reference and hypothesis sentences. Based on the result, multiple measures\n    can be computed, such as the word error rate.\n\n    Args:\n        reference: The reference sentence(s)\n        hypothesis: The hypothesis sentence(s)\n        reference_transform: The transformation(s) to apply to the reference string(s)\n        hypothesis_transform: The transformation(s) to apply to the hypothesis string(s)\n\n    Returns:\n        (WordOutput): The processed reference and hypothesis sentences\n\n    Raises:\n        ValueError: If one or more references are empty strings\n        ValueError: If after applying transforms, reference and hypothesis lengths don't match\n    \"\"\"\n    # validate input type\n    if isinstance(reference, str):\n        reference = [reference]\n    if isinstance(hypothesis, str):\n        hypothesis = [hypothesis]\n    if any(len(t) == 0 for t in reference):\n        raise ValueError(\"one or more references are empty strings\")\n\n    # pre-process reference and hypothesis by applying transforms\n    ref_transformed = _apply_transform(\n        reference, reference_transform, is_reference=True\n    )\n    hyp_transformed = _apply_transform(\n        hypothesis, hypothesis_transform, is_reference=False\n    )\n\n    if len(ref_transformed) != len(hyp_transformed):\n        raise ValueError(\n            \"After applying the transforms on the reference and hypothesis sentences, \"\n            f\"their lengths must match. \"\n            f\"Instead got {len(ref_transformed)} reference and \"\n            f\"{len(hyp_transformed)} hypothesis sentences.\"\n        )\n\n    # Map each word into a unique integer in order to compute\n    # word-level levenshtein distance\n    ref_as_ints, hyp_as_ints = _word2int(ref_transformed, hyp_transformed)\n\n    # keep track of total hits, substitutions, deletions and insertions\n    # across all input sentences\n    num_hits, num_substitutions, num_deletions, num_insertions = 0, 0, 0, 0\n\n    # also keep track of the total number of words in the reference and hypothesis\n    num_rf_words, num_hp_words = 0, 0\n\n    # anf finally, keep track of the alignment between each reference and hypothesis\n    alignments = []\n\n    for reference_sentence, hypothesis_sentence in zip(ref_as_ints, hyp_as_ints):\n        # Get the opcodes directly\n        opcodes = rapidfuzz.distance.Levenshtein.opcodes(\n            reference_sentence, hypothesis_sentence\n        )\n\n        subs = dels = ins = hits = 0\n        sentence_op_chunks = []\n\n        for tag, i1, i2, j1, j2 in opcodes:\n            # Create alignment chunk\n            sentence_op_chunks.append(\n                AlignmentChunk(\n                    type=tag,\n                    ref_start_idx=i1,\n                    ref_end_idx=i2,\n                    hyp_start_idx=j1,\n                    hyp_end_idx=j2,\n                )\n            )\n\n            # Update counts\n            if tag == \"equal\":\n                hits += i2 - i1\n            elif tag == \"replace\":\n                subs += i2 - i1\n            elif tag == \"delete\":\n                dels += i2 - i1\n            elif tag == \"insert\":\n                ins += j2 - j1\n\n        # Update global counts\n        num_hits += hits\n        num_substitutions += subs\n        num_deletions += dels\n        num_insertions += ins\n        num_rf_words += len(reference_sentence)\n        num_hp_words += len(hypothesis_sentence)\n        alignments.append(sentence_op_chunks)\n\n    # Compute all measures\n    S, D, I, H = num_substitutions, num_deletions, num_insertions, num_hits\n\n    wer = float(S + D + I) / float(H + S + D)\n    mer = float(S + D + I) / float(H + S + D + I)\n    wip = (\n        (float(H) / num_rf_words) * (float(H) / num_hp_words)\n        if num_hp_words &gt;= 1\n        else 0\n    )\n    wil = 1 - wip\n\n    # return all output\n    return WordOutput(\n        references=ref_transformed,\n        hypotheses=hyp_transformed,\n        alignments=alignments,\n        wer=wer,\n        mer=mer,\n        wil=wil,\n        wip=wip,\n        hits=num_hits,\n        substitutions=num_substitutions,\n        insertions=num_insertions,\n        deletions=num_deletions,\n    )\n</code></pre>"},{"location":"reference/transformations/","title":"transformations","text":""},{"location":"reference/transformations/#transformations","title":"transformations","text":"<p>This file is intended to provide the default transformation which need to be applied to input text in order to compute the WER (or similar measures).</p> <p>It also implements some alternative transformations which might be useful in specific use cases.</p>"},{"location":"reference/transformations/#transformations.cer_contiguous","title":"cer_contiguous  <code>module-attribute</code>","text":"<pre><code>cer_contiguous = Compose(\n    [\n        Strip(),\n        ReduceToSingleSentence(),\n        ReduceToListOfListOfChars(),\n    ]\n)\n</code></pre> <p>This can used instead of <code>cer_default</code> when the number of reference and hypothesis  sentences differ.</p>"},{"location":"reference/transformations/#transformations.cer_default","title":"cer_default  <code>module-attribute</code>","text":"<pre><code>cer_default = Compose(\n    [Strip(), ReduceToListOfListOfChars()]\n)\n</code></pre> <p>This is the default transformation when using <code>process_characters</code>. Each input string will  have its leading and tailing white space removed. Then each string is  transformed into a list with lists of strings, where each string is a single character.</p>"},{"location":"reference/transformations/#transformations.wer_contiguous","title":"wer_contiguous  <code>module-attribute</code>","text":"<pre><code>wer_contiguous = Compose(\n    [\n        RemoveMultipleSpaces(),\n        Strip(),\n        ReduceToSingleSentence(),\n        ReduceToListOfListOfWords(),\n    ]\n)\n</code></pre> <p>This is can be used instead of <code>wer_default</code> when the number of reference and hypothesis  sentences differ.</p>"},{"location":"reference/transformations/#transformations.wer_default","title":"wer_default  <code>module-attribute</code>","text":"<pre><code>wer_default = Compose(\n    [\n        RemoveMultipleSpaces(),\n        Strip(),\n        ReduceToListOfListOfWords(),\n    ]\n)\n</code></pre> <p>This is the default transformation when using <code>proces_words</code>. Each input string will  have its leading and tailing white space removed.  Thereafter multiple spaces between words are also removed.  Then each string is transformed into a list with lists of strings, where each string is a single word.</p>"},{"location":"reference/transformations/#transformations.wer_standardize","title":"wer_standardize  <code>module-attribute</code>","text":"<pre><code>wer_standardize = Compose(\n    [\n        ToLowerCase(),\n        ExpandCommonEnglishContractions(),\n        RemoveKaldiNonWords(),\n        RemoveWhiteSpace(replace_by_space=True),\n        RemoveMultipleSpaces(),\n        Strip(),\n        ReduceToListOfListOfWords(),\n    ]\n)\n</code></pre> <p>This transform attempts to standardize the strings by setting all characters to lower case, expanding common contractions, and removing non-words. Then the default operations are applied.</p>"},{"location":"reference/transformations/#transformations.wer_standardize_contiguous","title":"wer_standardize_contiguous  <code>module-attribute</code>","text":"<pre><code>wer_standardize_contiguous = Compose(\n    [\n        ToLowerCase(),\n        ExpandCommonEnglishContractions(),\n        RemoveKaldiNonWords(),\n        RemoveWhiteSpace(replace_by_space=True),\n        RemoveMultipleSpaces(),\n        Strip(),\n        ReduceToSingleSentence(),\n        ReduceToListOfListOfWords(),\n    ]\n)\n</code></pre> <p>This is the same as <code>wer_standize</code>, but this version can be usd when the number of reference and hypothesis sentences differ.</p>"},{"location":"reference/transforms/","title":"transforms","text":""},{"location":"reference/transforms/#transforms","title":"transforms","text":"<p>This file implements the building blocks for transforming a collection of input strings to the desired format in order to calculate the WER of CER.</p> <p>In principle, for word error rate calculations, every string of a sentence needs to be collapsed into a list of strings, where each string is a single word. This is done with transforms.ReduceToListOfListOfWords. A composition of multiple transformations must therefore always end with transforms.ReduceToListOfListOfWords.</p> <p>For the character error rate, every string of a sentence also needs to be collapsed into a list of strings, but here each string is a single character. This is done with transforms.ReduceToListOfListOfChars. Similarly, a composition of multiple transformations must therefore also always end with transforms.ReduceToListOfListOfChars.</p>"},{"location":"reference/transforms/#transforms.AbstractTransform","title":"AbstractTransform","text":"<p>               Bases: <code>object</code></p> <p>The base class of a Transform.</p> Source code in <code>src/jiwer/transforms.py</code> <pre><code>class AbstractTransform(object):\n    \"\"\"\n    The base class of a Transform.\n    \"\"\"\n\n    def __call__(self, sentences: Union[str, List[str]]):\n        \"\"\"\n        Transforms one or more strings.\n\n        Args:\n            sentences: The strings to transform.\n\n        Returns:\n            (Union[str, List[str]]): The transformed strings.\n\n        \"\"\"\n        if isinstance(sentences, str):\n            return self.process_string(sentences)\n        elif isinstance(sentences, list):\n            return self.process_list(sentences)\n        else:\n            raise ValueError(\n                \"input {} was expected to be a string or list of strings\".format(\n                    sentences\n                )\n            )\n\n    def process_string(self, s: str):\n        raise NotImplementedError()\n\n    def process_list(self, inp: List[str]):\n        return [self.process_string(s) for s in inp]\n</code></pre>"},{"location":"reference/transforms/#transforms.AbstractTransform.__call__","title":"__call__","text":"<pre><code>__call__(sentences)\n</code></pre> <p>Transforms one or more strings.</p> <p>Parameters:</p> Name Type Description Default <code>sentences</code> <code>Union[str, List[str]]</code> <p>The strings to transform.</p> required <p>Returns:</p> Type Description <code>Union[str, List[str]]</code> <p>The transformed strings.</p> Source code in <code>src/jiwer/transforms.py</code> <pre><code>def __call__(self, sentences: Union[str, List[str]]):\n    \"\"\"\n    Transforms one or more strings.\n\n    Args:\n        sentences: The strings to transform.\n\n    Returns:\n        (Union[str, List[str]]): The transformed strings.\n\n    \"\"\"\n    if isinstance(sentences, str):\n        return self.process_string(sentences)\n    elif isinstance(sentences, list):\n        return self.process_list(sentences)\n    else:\n        raise ValueError(\n            \"input {} was expected to be a string or list of strings\".format(\n                sentences\n            )\n        )\n</code></pre>"},{"location":"reference/transforms/#transforms.Compose","title":"Compose","text":"<p>               Bases: <code>object</code></p> <p>Chain multiple transformations back-to-back to create a pipeline combining multiple transformations.</p> <p>Note that each transformation needs to end with either <code>ReduceToListOfListOfWords</code> or <code>ReduceToListOfListOfChars</code>, depending on whether word error rate, or character error rate is desired.</p> Example <pre><code>import jiwer\n\njiwer.Compose([\n    jiwer.RemoveMultipleSpaces(),\n    jiwer.ReduceToListOfListOfWords()\n])\n</code></pre> Source code in <code>src/jiwer/transforms.py</code> <pre><code>class Compose(object):\n    \"\"\"\n    Chain multiple transformations back-to-back to create a pipeline combining multiple\n    transformations.\n\n    Note that each transformation needs to end with either `ReduceToListOfListOfWords`\n    or `ReduceToListOfListOfChars`, depending on whether word error rate,\n    or character error rate is desired.\n\n    Example:\n        ```python3\n        import jiwer\n\n        jiwer.Compose([\n            jiwer.RemoveMultipleSpaces(),\n            jiwer.ReduceToListOfListOfWords()\n        ])\n        ```\n    \"\"\"\n\n    def __init__(self, transforms: List[AbstractTransform]):\n        \"\"\"\n\n        Args:\n            transforms: The list of transformations to chain.\n        \"\"\"\n        self.transforms = transforms\n\n    def __call__(self, text):\n        for tr in self.transforms:\n            text = tr(text)\n\n        return text\n</code></pre>"},{"location":"reference/transforms/#transforms.Compose.__init__","title":"__init__","text":"<pre><code>__init__(transforms)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>transforms</code> <code>List[AbstractTransform]</code> <p>The list of transformations to chain.</p> required Source code in <code>src/jiwer/transforms.py</code> <pre><code>def __init__(self, transforms: List[AbstractTransform]):\n    \"\"\"\n\n    Args:\n        transforms: The list of transformations to chain.\n    \"\"\"\n    self.transforms = transforms\n</code></pre>"},{"location":"reference/transforms/#transforms.ExpandCommonEnglishContractions","title":"ExpandCommonEnglishContractions","text":"<p>               Bases: <code>AbstractTransform</code></p> <p>Replace common contractions such as <code>let's</code> to <code>let us</code>.</p> <p>Currently, this method will perform the following replacements. Note that <code>\u2423</code> is  used to indicate a space (<code></code>) to get around markdown rendering constrains.</p> Contraction transformed into <code>won't</code> <code>\u2423will not</code> <code>can't</code> <code>\u2423can not</code> <code>let's</code> <code>\u2423let us</code> <code>n't</code> <code>\u2423not</code> <code>'re</code> <code>\u2423are</code> <code>'s</code> <code>\u2423is</code> <code>'d</code> <code>\u2423would</code> <code>'ll</code> <code>\u2423will</code> <code>'t</code> <code>\u2423not</code> <code>'ve</code> <code>\u2423have</code> <code>'m</code> <code>\u2423am</code> Example <pre><code>import jiwer\n\nsentences = [\"she'll make sure you can't make it\", \"let's party!\"]\n\nprint(jiwer.ExpandCommonEnglishContractions()(sentences))\n# prints: [\"she will make sure you can not make it\", \"let us party!\"]\n</code></pre> Source code in <code>src/jiwer/transforms.py</code> <pre><code>class ExpandCommonEnglishContractions(AbstractTransform):\n    \"\"\"\n    Replace common contractions such as `let's` to `let us`.\n\n    Currently, this method will perform the following replacements. Note that `\u2423` is\n     used to indicate a space (` `) to get around markdown rendering constrains.\n\n    | Contraction   | transformed into |\n    | ------------- |:----------------:|\n    | `won't`       | `\u2423will not`      |\n    | `can't`       | `\u2423can not`       |\n    | `let's`       | `\u2423let us`        |\n    | `n't`         | `\u2423not`           |\n    | `'re`         | `\u2423are`           |\n    | `'s`          | `\u2423is`            |\n    | `'d`          | `\u2423would`         |\n    | `'ll`         | `\u2423will`          |\n    | `'t`          | `\u2423not`           |\n    | `'ve`         | `\u2423have`          |\n    | `'m`          | `\u2423am`            |\n\n    Example:\n        ```python\n        import jiwer\n\n        sentences = [\"she'll make sure you can't make it\", \"let's party!\"]\n\n        print(jiwer.ExpandCommonEnglishContractions()(sentences))\n        # prints: [\"she will make sure you can not make it\", \"let us party!\"]\n        ```\n\n    \"\"\"\n\n    def process_string(self, s: str):\n        # definitely a non exhaustive list\n\n        # specific words\n        s = re.sub(r\"won't\", \"will not\", s)\n        s = re.sub(r\"can\\'t\", \"can not\", s)\n        s = re.sub(r\"let\\'s\", \"let us\", s)\n\n        # general attachments\n        s = re.sub(r\"n\\'t\", \" not\", s)\n        s = re.sub(r\"\\'re\", \" are\", s)\n        s = re.sub(r\"\\'s\", \" is\", s)\n        s = re.sub(r\"\\'d\", \" would\", s)\n        s = re.sub(r\"\\'ll\", \" will\", s)\n        s = re.sub(r\"\\'t\", \" not\", s)\n        s = re.sub(r\"\\'ve\", \" have\", s)\n        s = re.sub(r\"\\'m\", \" am\", s)\n\n        return s\n</code></pre>"},{"location":"reference/transforms/#transforms.ReduceToListOfListOfChars","title":"ReduceToListOfListOfChars","text":"<p>               Bases: <code>AbstractTransform</code></p> <p>Transforms a single input sentence, or a list of input sentences, into a list with lists of characters, which is the expected format for calculating the edit operations between two input sentences on a character-level.</p> <p>A sentence is assumed to be a string. Each string is expected to contain only a single sentence.</p> Example <pre><code>import jiwer\n\nsentences = [\"hi\", \"this is an example\"]\n\nprint(jiwer.ReduceToListOfListOfChars()(sentences))\n# prints: [['h', 'i'], ['t', 'h', 'i', 's', ' ', 'i', 's', ' ', 'a', 'n', ' ', 'e', 'x', 'a', 'm', 'p', 'l', 'e']]\n</code></pre> Source code in <code>src/jiwer/transforms.py</code> <pre><code>class ReduceToListOfListOfChars(AbstractTransform):\n    \"\"\"\n    Transforms a single input sentence, or a list of input sentences, into\n    a list with lists of characters, which is the expected format for calculating the\n    edit operations between two input sentences on a character-level.\n\n    A sentence is assumed to be a string. Each string is expected to contain only a\n    single sentence.\n\n    Example:\n        ```python\n        import jiwer\n\n        sentences = [\"hi\", \"this is an example\"]\n\n        print(jiwer.ReduceToListOfListOfChars()(sentences))\n        # prints: [['h', 'i'], ['t', 'h', 'i', 's', ' ', 'i', 's', ' ', 'a', 'n', ' ', 'e', 'x', 'a', 'm', 'p', 'l', 'e']]\n        ```\n    \"\"\"\n\n    def process_string(self, s: str):\n        return [[w for w in s]]\n\n    def process_list(self, inp: List[str]):\n        sentence_collection = []\n\n        for sentence in inp:\n            list_of_words = self.process_string(sentence)[0]\n\n            sentence_collection.append(list_of_words)\n\n        if len(sentence_collection) == 0:\n            return [[]]\n\n        return sentence_collection\n</code></pre>"},{"location":"reference/transforms/#transforms.ReduceToListOfListOfWords","title":"ReduceToListOfListOfWords","text":"<p>               Bases: <code>AbstractTransform</code></p> <p>Transforms a single input sentence, or a list of input sentences, into a list with lists of words, which is the expected format for calculating the edit operations between two input sentences on a word-level.</p> <p>A sentence is assumed to be a string, where words are delimited by a token (such as <code></code>, space). Each string is expected to contain only a single sentence. Empty strings (no output) are removed for the list.</p> Example <pre><code>import jiwer\n\nsentences = [\"hi\", \"this is an example\"]\n\nprint(jiwer.ReduceToListOfListOfWords()(sentences))\n# prints: [['hi'], ['this', 'is', 'an, 'example']]\n</code></pre> Source code in <code>src/jiwer/transforms.py</code> <pre><code>class ReduceToListOfListOfWords(AbstractTransform):\n    \"\"\"\n    Transforms a single input sentence, or a list of input sentences, into\n    a list with lists of words, which is the expected format for calculating the\n    edit operations between two input sentences on a word-level.\n\n    A sentence is assumed to be a string, where words are delimited by a token\n    (such as ` `, space). Each string is expected to contain only a single sentence.\n    Empty strings (no output) are removed for the list.\n\n    Example:\n        ```python\n        import jiwer\n\n        sentences = [\"hi\", \"this is an example\"]\n\n        print(jiwer.ReduceToListOfListOfWords()(sentences))\n        # prints: [['hi'], ['this', 'is', 'an, 'example']]\n        ```\n    \"\"\"\n\n    def __init__(self, word_delimiter: str = \" \"):\n        \"\"\"\n        Args:\n            word_delimiter: the character which delimits words. Default is ` ` (space).\n        \"\"\"\n        self.word_delimiter = word_delimiter\n\n    def process_string(self, s: str):\n        return [[w for w in s.split(self.word_delimiter) if len(w) &gt;= 1]]\n\n    def process_list(self, inp: List[str]):\n        sentence_collection = []\n\n        for sentence in inp:\n            list_of_words = self.process_string(sentence)[0]\n\n            sentence_collection.append(list_of_words)\n\n        if len(sentence_collection) == 0:\n            return [[]]\n\n        return sentence_collection\n</code></pre>"},{"location":"reference/transforms/#transforms.ReduceToListOfListOfWords.__init__","title":"__init__","text":"<pre><code>__init__(word_delimiter=' ')\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>word_delimiter</code> <code>str</code> <p>the character which delimits words. Default is <code></code> (space).</p> <code>' '</code> Source code in <code>src/jiwer/transforms.py</code> <pre><code>def __init__(self, word_delimiter: str = \" \"):\n    \"\"\"\n    Args:\n        word_delimiter: the character which delimits words. Default is ` ` (space).\n    \"\"\"\n    self.word_delimiter = word_delimiter\n</code></pre>"},{"location":"reference/transforms/#transforms.ReduceToSingleSentence","title":"ReduceToSingleSentence","text":"<p>               Bases: <code>AbstractTransform</code></p> <p>Transforms multiple sentences into a single sentence. This operation can be useful when the number of reference and hypothesis sentences differ, and you want to do a minimal alignment over these lists. Note that this creates an invariance: <code>wer([a, b], [a, b])</code> might not be equal to <code>wer([b, a], [b, a])</code>.</p> Example <pre><code>import jiwer\n\nsentences = [\"hi\", \"this is an example\"]\n\nprint(jiwer.ReduceToSingleSentence()(sentences))\n# prints: ['hi this is an example']\n</code></pre> Source code in <code>src/jiwer/transforms.py</code> <pre><code>class ReduceToSingleSentence(AbstractTransform):\n    \"\"\"\n    Transforms multiple sentences into a single sentence.\n    This operation can be useful when the number of reference and hypothesis sentences\n    differ, and you want to do a minimal alignment over these lists.\n    Note that this creates an invariance: `wer([a, b], [a, b])` might not be equal to\n    `wer([b, a], [b, a])`.\n\n    Example:\n        ```python3\n        import jiwer\n\n        sentences = [\"hi\", \"this is an example\"]\n\n        print(jiwer.ReduceToSingleSentence()(sentences))\n        # prints: ['hi this is an example']\n        ```\n    \"\"\"\n\n    def __init__(self, word_delimiter: str = \" \"):\n        \"\"\"\n        :param word_delimiter: the character which delimits words. Default is ` ` (space).\n        \"\"\"\n        self.word_delimiter = word_delimiter\n\n    def process_string(self, s: str):\n        return s\n\n    def process_list(self, inp: List[str]):\n        filtered_inp = [i for i in inp if len(i) &gt;= 1]\n\n        if len(filtered_inp) == 0:\n            return []\n        else:\n            return [\"{}\".format(self.word_delimiter).join(filtered_inp)]\n</code></pre>"},{"location":"reference/transforms/#transforms.ReduceToSingleSentence.__init__","title":"__init__","text":"<pre><code>__init__(word_delimiter=' ')\n</code></pre> <p>:param word_delimiter: the character which delimits words. Default is <code></code> (space).</p> Source code in <code>src/jiwer/transforms.py</code> <pre><code>def __init__(self, word_delimiter: str = \" \"):\n    \"\"\"\n    :param word_delimiter: the character which delimits words. Default is ` ` (space).\n    \"\"\"\n    self.word_delimiter = word_delimiter\n</code></pre>"},{"location":"reference/transforms/#transforms.RemoveEmptyStrings","title":"RemoveEmptyStrings","text":"<p>               Bases: <code>AbstractTransform</code></p> <p>Remove empty strings from a list of strings.</p> Example <pre><code>import jiwer\n\nsentences = [\"\", \"this is an example\", \" \",  \"                \"]\n\nprint(jiwer.RemoveEmptyStrings()(sentences))\n# prints: ['this is an example']\n</code></pre> Source code in <code>src/jiwer/transforms.py</code> <pre><code>class RemoveEmptyStrings(AbstractTransform):\n    \"\"\"\n    Remove empty strings from a list of strings.\n\n    Example:\n        ```python\n        import jiwer\n\n        sentences = [\"\", \"this is an example\", \" \",  \"                \"]\n\n        print(jiwer.RemoveEmptyStrings()(sentences))\n        # prints: ['this is an example']\n        ```\n    \"\"\"\n\n    def process_string(self, s: str):\n        return s.strip()\n\n    def process_list(self, inp: List[str]):\n        return [s for s in inp if self.process_string(s) != \"\"]\n</code></pre>"},{"location":"reference/transforms/#transforms.RemoveKaldiNonWords","title":"RemoveKaldiNonWords","text":"<p>               Bases: <code>AbstractTransform</code></p> <p>Remove any word between <code>[]</code> and <code>&lt;&gt;</code>. This can be useful when working with hypotheses from the Kaldi project, which can output non-words such as <code>[laugh]</code> and <code>&lt;unk&gt;</code>.</p> Example <pre><code>import jiwer\n\nsentences = [\"you &lt;unk&gt; like [laugh]\"]\n\nprint(jiwer.RemoveKaldiNonWords()(sentences))\n\n# prints: [\"you  like \"]\n# note the extra spaces\n</code></pre> Source code in <code>src/jiwer/transforms.py</code> <pre><code>class RemoveKaldiNonWords(AbstractTransform):\n    \"\"\"\n    Remove any word between `[]` and `&lt;&gt;`. This can be useful when working\n    with hypotheses from the Kaldi project, which can output non-words such as\n    `[laugh]` and `&lt;unk&gt;`.\n\n    Example:\n        ```python\n        import jiwer\n\n        sentences = [\"you &lt;unk&gt; like [laugh]\"]\n\n        print(jiwer.RemoveKaldiNonWords()(sentences))\n\n        # prints: [\"you  like \"]\n        # note the extra spaces\n        ```\n    \"\"\"\n\n    def process_string(self, s: str):\n        return re.sub(r\"[&lt;\\[][^&gt;\\]]*[&gt;\\]]\", \"\", s)\n</code></pre>"},{"location":"reference/transforms/#transforms.RemoveMultipleSpaces","title":"RemoveMultipleSpaces","text":"<p>               Bases: <code>AbstractTransform</code></p> <p>Filter out multiple spaces between words.</p> Example <pre><code>import jiwer\n\nsentences = [\"this is   an   example \", \"  hello goodbye  \", \"  \"]\n\nprint(jiwer.RemoveMultipleSpaces()(sentences))\n# prints: ['this is an example ', \" hello goodbye \", \" \"]\n# note that there are still trailing spaces\n</code></pre> Source code in <code>src/jiwer/transforms.py</code> <pre><code>class RemoveMultipleSpaces(AbstractTransform):\n    \"\"\"\n    Filter out multiple spaces between words.\n\n    Example:\n        ```python\n        import jiwer\n\n        sentences = [\"this is   an   example \", \"  hello goodbye  \", \"  \"]\n\n        print(jiwer.RemoveMultipleSpaces()(sentences))\n        # prints: ['this is an example ', \" hello goodbye \", \" \"]\n        # note that there are still trailing spaces\n        ```\n\n    \"\"\"\n\n    def process_string(self, s: str):\n        return re.sub(r\"\\s\\s+\", \" \", s)\n\n    def process_list(self, inp: List[str]):\n        return [self.process_string(s) for s in inp]\n</code></pre>"},{"location":"reference/transforms/#transforms.RemovePunctuation","title":"RemovePunctuation","text":"<p>               Bases: <code>BaseRemoveTransform</code></p> <p>This transform filters out punctuation. The punctuation characters are defined as all unicode characters whose category name starts with <code>P</code>. See here for more information. Example:     <pre><code>import jiwer\n\nsentences = [\"this is an example!\", \"hello. goodbye\"]\n\nprint(jiwer.RemovePunctuation()(sentences))\n# prints: ['this is an example', \"hello goodbye\"]\n</code></pre></p> Source code in <code>src/jiwer/transforms.py</code> <pre><code>class RemovePunctuation(BaseRemoveTransform):\n    \"\"\"\n    This transform filters out punctuation. The punctuation characters are defined as\n    all unicode characters whose category name starts with `P`.\n    See [here](https://www.unicode.org/reports/tr44/#General_Category_Values) for more\n    information.\n    Example:\n        ```python\n        import jiwer\n\n        sentences = [\"this is an example!\", \"hello. goodbye\"]\n\n        print(jiwer.RemovePunctuation()(sentences))\n        # prints: ['this is an example', \"hello goodbye\"]\n        ```\n    \"\"\"\n\n    def __init__(self):\n        punctuation_characters = _get_punctuation_characters()\n        super().__init__(punctuation_characters)\n</code></pre>"},{"location":"reference/transforms/#transforms.RemoveSpecificWords","title":"RemoveSpecificWords","text":"<p>               Bases: <code>SubstituteWords</code></p> <p>Can be used to filter out certain words. As words are replaced with a <code></code> character, make sure to that <code>RemoveMultipleSpaces</code>, <code>Strip()</code> and <code>RemoveEmptyStrings</code> are present in the composition after <code>RemoveSpecificWords</code>.</p> Example <pre><code>import jiwer\n\nsentences = [\"yhe awesome\", \"the apple is not a pear\", \"yhe\"]\n\nprint(jiwer.RemoveSpecificWords([\"yhe\", \"the\", \"a\"])(sentences))\n# prints: ['  awesome', '  apple is not   pear', ' ']\n# note the extra spaces\n</code></pre> Source code in <code>src/jiwer/transforms.py</code> <pre><code>class RemoveSpecificWords(SubstituteWords):\n    \"\"\"\n    Can be used to filter out certain words.\n    As words are replaced with a ` ` character, make sure to that\n    `RemoveMultipleSpaces`, `Strip()` and `RemoveEmptyStrings` are present\n    in the composition _after_ `RemoveSpecificWords`.\n\n    Example:\n        ```python\n        import jiwer\n\n        sentences = [\"yhe awesome\", \"the apple is not a pear\", \"yhe\"]\n\n        print(jiwer.RemoveSpecificWords([\"yhe\", \"the\", \"a\"])(sentences))\n        # prints: ['  awesome', '  apple is not   pear', ' ']\n        # note the extra spaces\n        ```\n    \"\"\"\n\n    def __init__(self, words_to_remove: List[str]):\n        \"\"\"\n        Args:\n            words_to_remove: List of words to remove.\n        \"\"\"\n        mapping = {word: \" \" for word in words_to_remove}\n\n        super().__init__(mapping)\n</code></pre>"},{"location":"reference/transforms/#transforms.RemoveSpecificWords.__init__","title":"__init__","text":"<pre><code>__init__(words_to_remove)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>words_to_remove</code> <code>List[str]</code> <p>List of words to remove.</p> required Source code in <code>src/jiwer/transforms.py</code> <pre><code>def __init__(self, words_to_remove: List[str]):\n    \"\"\"\n    Args:\n        words_to_remove: List of words to remove.\n    \"\"\"\n    mapping = {word: \" \" for word in words_to_remove}\n\n    super().__init__(mapping)\n</code></pre>"},{"location":"reference/transforms/#transforms.RemoveWhiteSpace","title":"RemoveWhiteSpace","text":"<p>               Bases: <code>BaseRemoveTransform</code></p> <p>This transform filters out white space characters. Note that by default space (<code></code>) is also removed, which will make it impossible to split a sentence into a list of words by using <code>ReduceToListOfListOfWords</code> or <code>ReduceToSingleSentence</code>. This can be prevented by replacing all whitespace with the space character. If so, make sure that <code>jiwer.RemoveMultipleSpaces</code>, <code>Strip()</code> and <code>RemoveEmptyStrings</code> are present in the composition after <code>RemoveWhiteSpace</code>.</p> Example <pre><code>import jiwer\n\nsentences = [\"this is an example\", \"hello world \"]\n\nprint(jiwer.RemoveWhiteSpace()(sentences))\n# prints: [\"thisisanexample\", \"helloworld\"]\n\nprint(jiwer.RemoveWhiteSpace(replace_by_space=True)(sentences))\n# prints: [\"this is an example\", \"hello world  \"]\n# note the trailing spaces\n</code></pre> Source code in <code>src/jiwer/transforms.py</code> <pre><code>class RemoveWhiteSpace(BaseRemoveTransform):\n    \"\"\"\n    This transform filters out white space characters.\n    Note that by default space (` `) is also removed, which will make it impossible to\n    split a sentence into a list of words by using `ReduceToListOfListOfWords` or\n    `ReduceToSingleSentence`.\n    This can be prevented by replacing all whitespace with the space character.\n    If so, make sure that `jiwer.RemoveMultipleSpaces`,\n    `Strip()` and `RemoveEmptyStrings` are present in the composition _after_\n    `RemoveWhiteSpace`.\n\n    Example:\n        ```python\n        import jiwer\n\n        sentences = [\"this is an example\", \"hello world\\t\"]\n\n        print(jiwer.RemoveWhiteSpace()(sentences))\n        # prints: [\"thisisanexample\", \"helloworld\"]\n\n        print(jiwer.RemoveWhiteSpace(replace_by_space=True)(sentences))\n        # prints: [\"this is an example\", \"hello world  \"]\n        # note the trailing spaces\n        ```\n    \"\"\"\n\n    def __init__(self, replace_by_space: bool = False):\n        \"\"\"\n\n        Args:\n            replace_by_space: every white space character is replaced with a space (` `)\n        \"\"\"\n        characters = [c for c in string.whitespace]\n\n        if replace_by_space:\n            replace_token = \" \"\n        else:\n            replace_token = \"\"\n\n        super().__init__(characters, replace_token=replace_token)\n</code></pre>"},{"location":"reference/transforms/#transforms.RemoveWhiteSpace.__init__","title":"__init__","text":"<pre><code>__init__(replace_by_space=False)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>replace_by_space</code> <code>bool</code> <p>every white space character is replaced with a space (<code></code>)</p> <code>False</code> Source code in <code>src/jiwer/transforms.py</code> <pre><code>def __init__(self, replace_by_space: bool = False):\n    \"\"\"\n\n    Args:\n        replace_by_space: every white space character is replaced with a space (` `)\n    \"\"\"\n    characters = [c for c in string.whitespace]\n\n    if replace_by_space:\n        replace_token = \" \"\n    else:\n        replace_token = \"\"\n\n    super().__init__(characters, replace_token=replace_token)\n</code></pre>"},{"location":"reference/transforms/#transforms.Strip","title":"Strip","text":"<p>               Bases: <code>AbstractTransform</code></p> <p>Removes all leading and trailing spaces.</p> Example <pre><code>import jiwer\n\nsentences = [\" this is an example \", \"  hello goodbye  \", \"  \"]\n\nprint(jiwer.Strip()(sentences))\n# prints: ['this is an example', \"hello goodbye\", \"\"]\n# note that there is an empty string left behind which might need to be cleaned up\n</code></pre> Source code in <code>src/jiwer/transforms.py</code> <pre><code>class Strip(AbstractTransform):\n    \"\"\"\n    Removes all leading and trailing spaces.\n\n    Example:\n        ```python\n        import jiwer\n\n        sentences = [\" this is an example \", \"  hello goodbye  \", \"  \"]\n\n        print(jiwer.Strip()(sentences))\n        # prints: ['this is an example', \"hello goodbye\", \"\"]\n        # note that there is an empty string left behind which might need to be cleaned up\n        ```\n    \"\"\"\n\n    def process_string(self, s: str):\n        return s.strip()\n</code></pre>"},{"location":"reference/transforms/#transforms.SubstituteRegexes","title":"SubstituteRegexes","text":"<p>               Bases: <code>AbstractTransform</code></p> <p>Transform strings by substituting substrings matching regex expressions into another substring.</p> Example <pre><code>import jiwer\n\nsentences = [\"is the world doomed or loved?\", \"edibles are allegedly cultivated\"]\n\n# note: the regex string \"\\b(\\w+)ed\\b\", matches every word ending in 'ed',\n# and \"\\1\" stands for the first group ('\\w+). It therefore removes 'ed' in every match.\nprint(jiwer.SubstituteRegexes({r\"doom\": r\"sacr\", r\"\\b(\\w+)ed\\b\": r\"\\1\"})(sentences))\n\n# prints: [\"is the world sacr or lov?\", \"edibles are allegedly cultivat\"]\n</code></pre> Source code in <code>src/jiwer/transforms.py</code> <pre><code>class SubstituteRegexes(AbstractTransform):\n    r\"\"\"\n    Transform strings by substituting substrings matching regex expressions into\n    another substring.\n\n    Example:\n        ```python\n        import jiwer\n\n        sentences = [\"is the world doomed or loved?\", \"edibles are allegedly cultivated\"]\n\n        # note: the regex string \"\\b(\\w+)ed\\b\", matches every word ending in 'ed',\n        # and \"\\1\" stands for the first group ('\\w+). It therefore removes 'ed' in every match.\n        print(jiwer.SubstituteRegexes({r\"doom\": r\"sacr\", r\"\\b(\\w+)ed\\b\": r\"\\1\"})(sentences))\n\n        # prints: [\"is the world sacr or lov?\", \"edibles are allegedly cultivat\"]\n        ```\n    \"\"\"\n\n    def __init__(self, substitutions: Mapping[str, str]):\n        \"\"\"\n\n        Args:\n            substitutions: a mapping of regex expressions to replacement strings.\n        \"\"\"\n        self.substitutions = substitutions\n\n    def process_string(self, s: str):\n        for key, value in self.substitutions.items():\n            s = re.sub(key, value, s)\n\n        return s\n</code></pre>"},{"location":"reference/transforms/#transforms.SubstituteRegexes.__init__","title":"__init__","text":"<pre><code>__init__(substitutions)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>substitutions</code> <code>Mapping[str, str]</code> <p>a mapping of regex expressions to replacement strings.</p> required Source code in <code>src/jiwer/transforms.py</code> <pre><code>def __init__(self, substitutions: Mapping[str, str]):\n    \"\"\"\n\n    Args:\n        substitutions: a mapping of regex expressions to replacement strings.\n    \"\"\"\n    self.substitutions = substitutions\n</code></pre>"},{"location":"reference/transforms/#transforms.SubstituteWords","title":"SubstituteWords","text":"<p>               Bases: <code>AbstractTransform</code></p> <p>This transform can be used to replace a word into another word. Note that the whole word is matched. If the word you're attempting to substitute is a substring of another word it will not be affected. For example, if you're substituting <code>foo</code> into <code>bar</code>, the word <code>foobar</code> will NOT be substituted into <code>barbar</code>.</p> Example <pre><code>import jiwer\n\nsentences = [\"you're pretty\", \"your book\", \"foobar\"]\n\nprint(jiwer.SubstituteWords({\"pretty\": \"awesome\", \"you\": \"i\", \"'re\": \" am\", 'foo': 'bar'})(sentences))\n\n# prints: [\"i am awesome\", \"your book\", \"foobar\"]\n</code></pre> Source code in <code>src/jiwer/transforms.py</code> <pre><code>class SubstituteWords(AbstractTransform):\n    \"\"\"\n    This transform can be used to replace a word into another word.\n    Note that the whole word is matched. If the word you're attempting to substitute\n    is a substring of another word it will not be affected.\n    For example, if you're substituting `foo` into `bar`, the word `foobar` will NOT\n    be substituted into `barbar`.\n\n    Example:\n        ```python\n        import jiwer\n\n        sentences = [\"you're pretty\", \"your book\", \"foobar\"]\n\n        print(jiwer.SubstituteWords({\"pretty\": \"awesome\", \"you\": \"i\", \"'re\": \" am\", 'foo': 'bar'})(sentences))\n\n        # prints: [\"i am awesome\", \"your book\", \"foobar\"]\n        ```\n\n    \"\"\"\n\n    def __init__(self, substitutions: Mapping[str, str]):\n        \"\"\"\n        Args:\n            substitutions: A mapping of words to replacement words.\n        \"\"\"\n        self.substitutions = substitutions\n\n    def process_string(self, s: str):\n        for key, value in self.substitutions.items():\n            s = re.sub(r\"\\b{}\\b\".format(re.escape(key)), value, s)\n\n        return s\n</code></pre>"},{"location":"reference/transforms/#transforms.SubstituteWords.__init__","title":"__init__","text":"<pre><code>__init__(substitutions)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>substitutions</code> <code>Mapping[str, str]</code> <p>A mapping of words to replacement words.</p> required Source code in <code>src/jiwer/transforms.py</code> <pre><code>def __init__(self, substitutions: Mapping[str, str]):\n    \"\"\"\n    Args:\n        substitutions: A mapping of words to replacement words.\n    \"\"\"\n    self.substitutions = substitutions\n</code></pre>"},{"location":"reference/transforms/#transforms.ToLowerCase","title":"ToLowerCase","text":"<p>               Bases: <code>AbstractTransform</code></p> <p>Convert every character into lowercase. Example:     <pre><code>import jiwer\n\nsentences = [\"You're PRETTY\"]\n\nprint(jiwer.ToLowerCase()(sentences))\n\n# prints: [\"you're pretty\"]\n</code></pre></p> Source code in <code>src/jiwer/transforms.py</code> <pre><code>class ToLowerCase(AbstractTransform):\n    \"\"\"\n    Convert every character into lowercase.\n    Example:\n        ```python\n        import jiwer\n\n        sentences = [\"You're PRETTY\"]\n\n        print(jiwer.ToLowerCase()(sentences))\n\n        # prints: [\"you're pretty\"]\n        ```\n    \"\"\"\n\n    def process_string(self, s: str):\n        return s.lower()\n</code></pre>"},{"location":"reference/transforms/#transforms.ToUpperCase","title":"ToUpperCase","text":"<p>               Bases: <code>AbstractTransform</code></p> <p>Convert every character to uppercase.</p> Example <pre><code>import jiwer\n\nsentences = [\"You're amazing\"]\n\nprint(jiwer.ToUpperCase()(sentences))\n\n# prints: [\"YOU'RE AMAZING\"]\n</code></pre> Source code in <code>src/jiwer/transforms.py</code> <pre><code>class ToUpperCase(AbstractTransform):\n    \"\"\"\n    Convert every character to uppercase.\n\n    Example:\n        ```python\n        import jiwer\n\n        sentences = [\"You're amazing\"]\n\n        print(jiwer.ToUpperCase()(sentences))\n\n        # prints: [\"YOU'RE AMAZING\"]\n        ```\n    \"\"\"\n\n    def process_string(self, s: str):\n        return s.upper()\n</code></pre>"}]}